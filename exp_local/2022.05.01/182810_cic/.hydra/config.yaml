agent:
  _target_: agent.cic.CICAgent
  name: cic
  reward_free: ${reward_free}
  obs_type: ???
  obs_shape: ???
  action_shape: ???
  device: ${device}
  lr: 0.0001
  critic_target_tau: 0.01
  update_every_steps: 2
  use_tb: ${use_tb}
  use_wandb: ${use_wandb}
  num_expl_steps: 2000
  hidden_dim: 1024
  feature_dim: 1024
  stddev_schedule: 0.2
  stddev_clip: 0.3
  skill_dim: 64
  scale: 1.0
  update_skill_every_step: 50
  nstep: 3
  batch_size: 1024
  project_skill: true
  init_critic: true
  rew_type: og
  update_rep: true
  temp: 0.5
reward_free: true
domain: quadruped
obs_type: states
frame_stack: 3
action_repeat: 1
discount: 0.99
num_train_frames: 2000010
num_seed_frames: 4000
eval_every_frames: 10000
num_eval_episodes: 10
snapshots:
- 100000
- 300000
- 500000
- 700000
- 1000000
- 1200000
- 1400000
- 1600000
- 1800000
- 2000000
snapshot_dir: ../../../pretrained_models/${obs_type}/${domain}/${agent.name}/${experiment}
replay_buffer_size: 1000000
replay_buffer_num_workers: 4
batch_size: ${agent.batch_size}
nstep: ${agent.nstep}
update_encoder: true
seed: 1
device: cuda
save_video: true
save_train_video: false
use_tb: false
use_wandb: false
experiment: INIT_QUAD
